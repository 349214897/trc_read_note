### 几点宏观见解

1. 我觉得语音,图像识别和翻译之所以在网络中表现出了很好的效果,是因为网络结构本来包含了合理的先验信息,比如说卷积对应了图像的局部特征,LSTM对应了序列,这都是结构先天的对问题的固有适应,就像算法里面的数据结构加算法,合理的抽象结构会极大地简化问题的求解

2. 强化学习与端到端及中间层等价替换,现在强化学习之所以应用有限,是应为不可解释性太强,而且一旦出现问题就难以调试和定为解决问题,那么借鉴encode-decode的思想,在网络中间引入节点,进行等价替换,在对这些节点的参数作分析,是不是就可以提升可解释性

3. 结构和结构属性天然的存储了知识,而现在的网络在固定结构上,调整属性(即权值参数)来适应单一问题,相当于改变了网络的知识结构,这样势必学到了一种目标,就丢弃了另一种目标,那么是不是可以假设有一张巨大的网络,没学到一点知识,就对这个结构模块固定,然后在学习其他的,这样就可以完成概念的聚合了.即完成了元认知.

4. 网络学习有两种一种是结构反馈,一种是数据反馈,我们是不是可以在数据反馈上多思考一点,找到突破.形成闭环.

5. 用卷积实现序列的功能

6. 一种新的模型之间的协作范式
