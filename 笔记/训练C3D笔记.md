### 训练不出车道线问题
将l2loss的diff中乘的sigmoid去掉就可,不然初始化时diff在e-10次方数量级,基本不调整参数
### 中心点出现锯齿,不在一条线上
可能是因为下取整引起的,也有可能是引入多帧图片引起的,需排查
### 感觉学到的时序特征不是很明显,比如说前四个输入为0,最后用原图片时结果差异不大,疑似3*3*3卷积核学习效果不理想,可以尝试用一个1*3*3和一个3*1*1代替,也有可能是加的C3D层数不足引起的
### 和单帧模型在G7上测试对比效果不理想,可能是用来训练的数据太少,加全数据训练排查
### 出现过一次loss训练后变nan的情况,疑似lr设的不合理,或者其他情况,需排查
### 初始模型和初始学习率选择有必要作对比实验

训练情况
两层3*3*3比一层5*9*9效果好很多,容易学且效果好
将乘以sigmoid去掉,能训练出车道线
以下步骤能提升训练效果:
1.先固定原始模型的2dconv参数,训练C3D核参数
2.在1稳定后在整体放开学习率
上述步骤可能会引起陷入局部最优的情况,造成不能比较好的学习到时序特征,需要对比验证下

4.25本地训练采用的是上周五训练的80000次模型(数据只用到了2d_28756),初始学习率为0.001,用的是新的caffe-apollo,看下学习效果是怎么样,但是新的caffe-apollo训练时各分项loss没显示出来,切可能sigmoid附在乘法项上,需确定这个问题是否有影响(训练到36000次,变化不大),models_lr0001 models_lr0000001是初始学习率为0.0000001
4.25share0上训练的初始网络为原来的迭代50000次的base网络,学习率都放开了,看下全部参数一次性参加训练效果是什么样的

4.20(周五)训练的模型是在老caffe-apollo上,去掉了sigmoid乘法项,用的是之src-50000次迭代model训练后的结果,效果存在中心线回归不准

4.25晚十点开始用全数据及显示loss情况训练

4.26准备训练伪3D网络,现在后面两层都是用24个卷积核,可以试下在倒数第二层将24个卷积核变成128,或者其他的试下,然后再分别加上伪3d试下效果

### 4.27后改进方法
1.一个加入多个batch,加入shuffle,不然学习的参数在另一批数据又被过度调整
2.加入伪3d训练

### 5.11加入分组飞伪3d训练后,检测线段变短(在0520训练的真3d模型来看,检测线段也变短了,初步确定是加入新的分组训练引起的)

### 5.13加入relu和bias_term后,有问题,是因为cudnn的缘故不支持c3drelu,代码已提交显示正常.

### 5.20训练两阶段loss,一个为前四帧预测loss,一个为当前帧检测loss,发现效果不好,可能是训练方式引起的问题

### 5.23真3d训练时,当group_loss scale设为100时会发散,设为0.1时,会出现总loss降低,group_loss上升
**微软cvpr2017oral中级联网络参数比较大,速度比较慢,但是其注意力机制是否可以借鉴到c3d中**

## 5.30 开始采用正交法训练模型
1. 加两层c3d,一层64个,一层24个,batch_size为5,最后一个conv8_4,用了drop_out,开放了所有的学习参数,加了relu,premodel为50000次模型
2. 9层不放开参数(share0上),待训练(传奇0321nobn模型做premodel)
3. 9层开放前面参数(传奇0321nobn模型做premodel)
5. 9层开放参数(50000模型)
4. 5层不放开前面参数训练(nobn模型)
5. 缩小一倍输入加deconv
6. 缩小一倍减去pool3
7. 缩小一倍入c3d,和标准输入concat
8. 每一种添加不同的dropout处理
9. 添加c3d,batchnorm
10. 弄清楚正则化,BN,dropout的内在联系区别,使用场景,以及featuremap的BN是否真的可以和卷积核参数的BN等价
11. c3d数据层认真规划
**12. 接conv9_1做训练**

### 5.31在训模型结构及位置
1. (本地c3d,64,24,5frame,conv8_4用dropout,开放了学习参数,加了relu,premodel为50000次模型)
2. (share0显卡id1上,frame9,4个layer3d,加dropout,固定前面参数,加了relu,premodel为nobn)
3. (share0显卡id2上,frame5,2个layer3d,加dropout,固定前面参数,加了relu,premodel为nobn)
4. (share0显卡id3上,frame5,2个layer3d,利用conv9做c3d输入,加dropout,固定前面参数,加了relu,premodel为nobn)
